/**
 * File Vectorization Service
 * 
 * Handles content extraction from files and vector generation for similarity search.
 * Supports text files, PDFs, and other document formats.
 */

import fs from 'fs';
import path from 'path';
import { createFileUploadVector } from '../../db/fileUploadVectors/index.js';

// Track files currently being processed to avoid duplicates
const processingFiles = new Set();

/**
 * Check if a file is currently being processed
 * @param {number} fileId - The file ID
 * @returns {boolean} - True if file is being processed
 */
export function isFileInProcessing(fileId) {
  return processingFiles.has(fileId);
}

/**
 * Extract content from file and create vector embeddings
 * @param {string} filePath - Path to the file
 * @param {number} fileId - Database file ID
 * @param {string} mimeType - File MIME type
 * @param {Object} pool - Database connection pool
 * @param {string} schemaName - Database schema name
 */
export async function extractAndVectorizeContent(filePath, fileId, mimeType, pool, schemaName) {
  if (processingFiles.has(fileId)) {
    console.log(`File ${fileId} is already being processed, skipping...`);
    return;
  }

  processingFiles.add(fileId);
  
  try {
    console.log(`Starting content extraction for file ${fileId} (${mimeType})`);
    
    // Extract text content based on file type
    let textContent = '';
    
    if (mimeType.startsWith('text/') || mimeType === 'application/json') {
      // Handle text files
      textContent = await extractTextContent(filePath);
    } else if (mimeType === 'application/pdf') {
      // Handle PDF files (placeholder for future PDF processing)
      console.log('PDF processing not yet implemented');
      return;
    } else {
      console.log(`Unsupported file type for vectorization: ${mimeType}`);
      return;
    }

    if (!textContent || textContent.trim().length === 0) {
      console.log(`No extractable text content found in file ${fileId}`);
      return;
    }

    // Chunk the content for better vector search
    const chunks = chunkText(textContent, 1000, 200);
    console.log(`Created ${chunks.length} chunks from file ${fileId}`);

    // Create vector embeddings for each chunk
    // Note: This is a placeholder - actual vector generation would require
    // an embedding service like OpenAI embeddings or local models
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      // Placeholder vector (in practice, this would be generated by an embedding model)
      const vector = generatePlaceholderVector(chunk);
      
      // Store the vector in the database
      const client = await pool.connect();
      try {
        await client.query(`SET search_path TO ${schemaName}, public;`);
        await createFileUploadVector({
          file_upload_id: fileId,
          chunk_index: i,
          chunk_text: chunk,
          vector: vector,
          metadata: {
            chunk_size: chunk.length,
            total_chunks: chunks.length
          }
        }, client);
      } finally {
        client.release();
      }
    }

    console.log(`Successfully vectorized file ${fileId} with ${chunks.length} chunks`);
    
  } catch (error) {
    console.error(`Error vectorizing file ${fileId}:`, error);
    throw error;
  } finally {
    processingFiles.delete(fileId);
  }
}

/**
 * Extract text content from a file
 * @param {string} filePath - Path to the file
 * @returns {Promise<string>} - Extracted text content
 */
async function extractTextContent(filePath) {
  try {
    const content = await fs.promises.readFile(filePath, 'utf8');
    return content;
  } catch (error) {
    console.error(`Error reading file ${filePath}:`, error);
    throw new Error(`Failed to read file: ${error.message}`);
  }
}

/**
 * Split text into overlapping chunks
 * @param {string} text - Text to chunk
 * @param {number} chunkSize - Size of each chunk
 * @param {number} overlap - Overlap between chunks
 * @returns {string[]} - Array of text chunks
 */
function chunkText(text, chunkSize = 1000, overlap = 200) {
  const chunks = [];
  let start = 0;
  
  while (start < text.length) {
    const end = Math.min(start + chunkSize, text.length);
    const chunk = text.slice(start, end);
    
    if (chunk.trim().length > 0) {
      chunks.push(chunk.trim());
    }
    
    // Move start position with overlap
    start = end - overlap;
    
    // Avoid infinite loop if chunk is smaller than overlap
    if (start <= 0) start = end;
  }
  
  return chunks;
}

/**
 * Generate a placeholder vector for development
 * In production, this would call an actual embedding service
 * @param {string} text - Text to vectorize
 * @returns {number[]} - Vector representation
 */
function generatePlaceholderVector(text) {
  // Generate a simple hash-based vector for development
  // This is NOT suitable for production use
  const vector = new Array(384).fill(0); // 384-dimensional vector
  
  for (let i = 0; i < text.length; i++) {
    const charCode = text.charCodeAt(i);
    vector[charCode % 384] += 1;
  }
  
  // Normalize the vector
  const magnitude = Math.sqrt(vector.reduce((sum, val) => sum + val * val, 0));
  if (magnitude > 0) {
    for (let i = 0; i < vector.length; i++) {
      vector[i] = vector[i] / magnitude;
    }
  }
  
  return vector;
}